{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Implementasi NARM untuk pengerjaan tugas akhir"],"metadata":{"id":"qmz558obRCbd"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iFptRMaDShxJ","executionInfo":{"status":"ok","timestamp":1746789419168,"user_tz":-420,"elapsed":13481,"user":{"displayName":"18221083 Nazhif Haidar Putra Wibowo","userId":"14295694113135502399"}},"outputId":"a824be3a-38f5-4395-8741-a06002ccc37b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mlflow\n","  Downloading mlflow-2.22.0-py3-none-any.whl.metadata (30 kB)\n","Collecting mlflow-skinny==2.22.0 (from mlflow)\n","  Downloading mlflow_skinny-2.22.0-py3-none-any.whl.metadata (31 kB)\n","Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.0)\n","Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.6)\n","Collecting alembic!=1.10.0,<2 (from mlflow)\n","  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n","Collecting docker<8,>=4.0.0 (from mlflow)\n","  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n","Collecting graphene<4 (from mlflow)\n","  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n","Collecting gunicorn<24 (from mlflow)\n","  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n","Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.8)\n","Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.10.0)\n","Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.2)\n","Requirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.2.2)\n","Requirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (18.1.0)\n","Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.6.1)\n","Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.2)\n","Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.40)\n","Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (5.5.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (8.1.8)\n","Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (3.1.1)\n","Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.22.0->mlflow)\n","  Downloading databricks_sdk-0.52.0-py3-none-any.whl.metadata (39 kB)\n","Collecting fastapi<1 (from mlflow-skinny==2.22.0->mlflow)\n","  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n","Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (3.1.44)\n","Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (8.7.0)\n","Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (1.16.0)\n","Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (1.16.0)\n","Requirement already satisfied: packaging<25 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (24.2)\n","Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (5.29.4)\n","Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (2.11.4)\n","Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (6.0.2)\n","Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (2.32.3)\n","Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.5.3)\n","Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (4.13.2)\n","Collecting uvicorn<1 (from mlflow-skinny==2.22.0->mlflow)\n","  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.1.3)\n","Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.4.0)\n","Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\n","Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\n","Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\n","Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n","  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n","Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n","  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.3)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.1)\n","Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (2.38.0)\n","Collecting starlette<0.47.0,>=0.40.0 (from fastapi<1->mlflow-skinny==2.22.0->mlflow)\n","  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow) (4.0.12)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.0->mlflow) (3.21.0)\n","Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.2.18)\n","Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (75.2.0)\n","Requirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (0.37b0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (2025.4.26)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==2.22.0->mlflow) (0.16.0)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.17.2)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow) (5.0.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (4.9.1)\n","Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow) (4.9.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow) (1.3.1)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.6.1)\n","Downloading mlflow-2.22.0-py3-none-any.whl (29.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mlflow_skinny-2.22.0-py3-none-any.whl (6.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading databricks_sdk-0.52.0-py3-none-any.whl (700 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m700.2/700.2 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n","Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: uvicorn, gunicorn, graphql-core, starlette, graphql-relay, docker, alembic, graphene, fastapi, databricks-sdk, mlflow-skinny, mlflow\n","Successfully installed alembic-1.15.2 databricks-sdk-0.52.0 docker-7.1.0 fastapi-0.115.12 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.22.0 mlflow-skinny-2.22.0 starlette-0.46.2 uvicorn-0.34.2\n","Collecting ijson\n","  Downloading ijson-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n","Downloading ijson-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.0/135.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ijson\n","Successfully installed ijson-3.4.0\n"]}],"source":["!pip install mlflow\n","!pip install ijson"]},{"cell_type":"code","source":["class objectview(object):\n","    def __init__(self, d):\n","        self.__dict__ = {\n","            k: objectview(v) if isinstance(v, dict) else v\n","            for k, v in d.items()\n","        }"],"metadata":{"id":"1fSLYzQuUX_y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas  as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch.nn as nn\n","import torch\n","import mlflow\n","import torch.nn.functional as F\n","from sklearn.model_selection import train_test_split\n","import joblib\n","from sklearn.preprocessing import LabelEncoder\n","import ast\n","import gdown\n","from google.colab import drive\n","from tqdm import tqdm\n","from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n","from torch.utils.data import Dataset, DataLoader\n","import random\n","from tqdm import tqdm\n","from collections import Counter, defaultdict\n","import re\n","from nltk.tokenize import word_tokenize\n","import nltk\n","import warnings\n","warnings.filterwarnings('ignore')\n","import os\n","import logging\n","logging.getLogger(\"mlflow\").setLevel(logging.ERROR)"],"metadata":{"id":"ONrsT8hJQ9pH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"loEqnTQ9UHPp","executionInfo":{"status":"ok","timestamp":1746789456244,"user_tz":-420,"elapsed":26850,"user":{"displayName":"18221083 Nazhif Haidar Putra Wibowo","userId":"14295694113135502399"}},"outputId":"d50a1223-d3ed-4b2b-9ded-8fef65d9fed5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Preprocessing"],"metadata":{"id":"V58K1PdDSSks"}},{"cell_type":"code","source":["PROJECT_PATH = '/content/drive/My Drive/TA/Implementasi'\n","DATASETS_PATH = PROJECT_PATH + '/datasets'\n","PROCESSED_DATA_PATH = PROJECT_PATH + '/data/processed'"],"metadata":{"id":"9ztfvSpJUCGH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Download the sequences and label encoder"],"metadata":{"id":"SGCWsoP3SyOW"}},{"cell_type":"code","source":["def download_drive_file(file_id, output_file):\n","    try:\n","        url = f'https://drive.google.com/uc?id={file_id}'\n","\n","        gdown.download(url, output_file, quiet=False)\n","\n","        print(f\"File downloaded successfully: {output_file}\")\n","    except Exception as e:\n","        print(f\"An error occurred while downloading the file: {e}\")"],"metadata":{"id":"rzQOk7fvS4ca"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# download_drive_file('1dMKbq9sawiAVH9Z4Nh2c2ZsZ3nle1-1Q','label_encoder.joblib')"],"metadata":{"id":"OEDGjtBES4Gg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load Sequences"],"metadata":{"id":"xng3elwPQ-fJ"}},{"cell_type":"code","source":["# sequences = pd.read_csv('data_joined.json')\n","# display(sequences.head())\n","# print(len(sequences))\n","\n","# Load the label encoder\n","label_encoder = joblib.load(DATASETS_PATH + '/product_id_encoder.joblib')"],"metadata":{"id":"eb8-tdCEQ9y2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import ijson\n","import json\n","import decimal\n","\n","class DecimalEncoder(json.JSONEncoder):\n","    def default(self, obj):\n","        if isinstance(obj, decimal.Decimal):\n","            return float(obj)\n","        return super(DecimalEncoder, self).default(obj)\n","\n","\n","file_path = PROCESSED_DATA_PATH + '/data_joined.json'\n","\n","def count_items_in_json(file_path):\n","    with open(file_path, 'r') as f:\n","        return sum(1 for _ in ijson.items(f, 'item'))\n","\n","def convert_decimal_to_float(obj):\n","    if isinstance(obj, decimal.Decimal):\n","        return float(obj)\n","    elif isinstance(obj, dict):\n","        return {k: convert_decimal_to_float(v) for k, v in obj.items()}\n","    elif isinstance(obj, list):\n","        return [convert_decimal_to_float(i) for i in obj]\n","    return obj\n","\n","def read_sequences(type_):\n","    if type_ == 'normal':\n","        return pd.read_csv(DATASETS_PATH + '/sequences.csv')[\"sequence\"]\n","    elif type_ == 'complete':\n","        items = []\n","        with open(file_path, 'r') as f:\n","            objects = ijson.items(f, 'item')\n","\n","            for i, obj in enumerate(tqdm(objects, desc=\"Reading data...\")):\n","                items.append(convert_decimal_to_float(obj))\n","\n","        return items\n","    else:\n","        raise ValueError(\"Invalid type. Expected 'normal' or 'complete'.\")\n","\n","# sequences = create_full_sequence(sessions)\n","sequences = read_sequences('complete')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PvfG8ZjoT9DH","executionInfo":{"status":"ok","timestamp":1746789573032,"user_tz":-420,"elapsed":34991,"user":{"displayName":"18221083 Nazhif Haidar Putra Wibowo","userId":"14295694113135502399"}},"outputId":"321dcfd6-2760-4d83-a63f-a33bc4795ce0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Reading data...: 1182181it [00:34, 34028.46it/s]\n"]}]},{"cell_type":"markdown","source":["read the head of the data"],"metadata":{"id":"VEWcsSAdZg2L"}},{"cell_type":"code","source":["print(json.dumps(sequences[:5], cls=DecimalEncoder, indent=4))\n","print(len(sequences))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xSZrHAS2Zeg2","executionInfo":{"status":"ok","timestamp":1746789573098,"user_tz":-420,"elapsed":64,"user":{"displayName":"18221083 Nazhif Haidar Putra Wibowo","userId":"14295694113135502399"}},"outputId":"a5933ea8-4c04-43de-cfa7-8fa009cbb9b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[\n","    {\n","        \"session_id\": 0,\n","        \"sequence\": [\n","            {\n","                \"id\": \"B0BFDL54Y7\",\n","                \"title\": \"salad in food cutter slicer veg vegetable with wokii potato container garlic for onion dicer butadi blue chopper acrylonitrile <unk> mini\",\n","                \"price\": 15.99,\n","                \"label\": 489206\n","            },\n","            {\n","                \"id\": \"B0BFDR9X13\",\n","                \"title\": \"salad in grey food cutter slicer veg vegetable with wokii potato container garlic for onion dicer butadi green chopper acrylonitrile <unk> mini\",\n","                \"price\": 14.99,\n","                \"label\": 489237\n","            },\n","            {\n","                \"id\": \"B07J4WF8VH\",\n","                \"title\": \"interchangeable salad food stainless cutter set slicer fruits inserts vegetable with potato garlic steel onion vinsani chopper white cheese blade kitchen <unk>\",\n","                \"price\": 16.99,\n","                \"label\": 142933\n","            },\n","            {\n","                \"id\": \"B07Y21LDJX\",\n","                \"title\": \"abs replaceable function separator premium in stainless cutter slicer fruits julienne vegetable plastic grater with potato steel for adov onion multi blue egg mandoline chopper guard kitchen hand <unk>\",\n","                \"price\": 21.99,\n","                \"label\": 188025\n","            },\n","            {\n","                \"id\": \"B07Y227WNJ\",\n","                \"title\": \"abs replaceable function separator premium in grey stainless cutter slicer fruits julienne vegetable plastic grater with potato steel for adov onion multi egg mandoline chopper guard kitchen hand <unk>\",\n","                \"price\": 21.99,\n","                \"label\": 188028\n","            }\n","        ],\n","        \"length\": 5\n","    },\n","    {\n","        \"session_id\": 1,\n","        \"sequence\": [\n","            {\n","                \"id\": \"B07FM2GLNQ\",\n","                \"title\": \"buttons illuminated verto rubber mac ergonomic wireless receiver storable with right micro mouse usb for trust dpi laptop pc users black hand vertical red\",\n","                \"price\": 24.99,\n","                \"label\": 133985\n","            },\n","            {\n","                \"id\": \"B07GZW3P4W\",\n","                \"title\": \"answer call trio blocking pack nuisance phone handset black <unk> bt machine with home and\",\n","                \"price\": 12.99,\n","                \"label\": 138876\n","            },\n","            {\n","                \"id\": \"B095NNZCR6\",\n","                \"title\": \"bedshe panels sheer curtain bedsure window cm curtains polyester for bedroom voile pair wide net drop white <unk>\",\n","                \"price\": 12.99,\n","                \"label\": 315348\n","            }\n","        ],\n","        \"length\": 3\n","    },\n","    {\n","        \"session_id\": 2,\n","        \"sequence\": [\n","            {\n","                \"id\": \"B0021L95HU\",\n","                \"title\": \"mg acid high omega multicoloured epa seas multivitamins fish with cod and tablets strength plus liver dha vitamin capsules seven folic oil biotin <unk>\",\n","                \"price\": 6.67,\n","                \"label\": 19817\n","            },\n","            {\n","                \"id\": \"B07DDL77RY\",\n","                \"title\": \"plus omega liver maroon capsules seven seas oil multivitamins fish cod <unk>\",\n","                \"price\": 8.66,\n","                \"label\": 129680\n","            },\n","            {\n","                \"id\": \"B07DDL77RY\",\n","                \"title\": \"plus omega liver maroon capsules seven seas oil multivitamins fish cod <unk>\",\n","                \"price\": 8.66,\n","                \"label\": 129680\n","            },\n","            {\n","                \"id\": \"B002KA1FZC\",\n","                \"title\": \"plus plastic omega liver capsules seven multicoloured seas oil fish cod\",\n","                \"price\": 7.49,\n","                \"label\": 20979\n","            }\n","        ],\n","        \"length\": 4\n","    },\n","    {\n","        \"session_id\": 3,\n","        \"sequence\": [\n","            {\n","                \"id\": \"B0B2WSZYL2\",\n","                \"title\": \"hoover replacement in grey clean rotator upright nozzle end vacuum shark dusting and crevice for abcsharkcrevicebrushtool tool away lift abc cleaner duo attachment brush products compatible <unk>\",\n","                \"price\": 9.99,\n","                \"label\": 443147\n","            },\n","            {\n","                \"id\": \"B000I8XZ7O\",\n","                \"title\": \"rubie child skeleton official boys white house black haunted costume large <unk> halloween\",\n","                \"price\": 8.3,\n","                \"label\": 12620\n","            },\n","            {\n","                \"id\": \"B000I90TAO\",\n","                \"title\": \"rubie skeleton <unk> official white house small black haunted costume boy halloween\",\n","                \"price\": 5.99,\n","                \"label\": 12621\n","            }\n","        ],\n","        \"length\": 3\n","    },\n","    {\n","        \"session_id\": 4,\n","        \"sequence\": [\n","            {\n","                \"id\": \"B00LW1APOC\",\n","                \"title\": \"wall pack frames dcor kg command to holds ef of mounting free and signs for mirrors foam damage hanging picture adhesive strips white medium pictures up\",\n","                \"price\": 7.5,\n","                \"label\": 55082\n","            },\n","            {\n","                \"id\": \"B00LW1APOC\",\n","                \"title\": \"wall pack frames dcor kg command to holds ef of mounting free and signs for mirrors foam damage hanging picture adhesive strips white medium pictures up\",\n","                \"price\": 7.5,\n","                \"label\": 55082\n","            },\n","            {\n","                \"id\": \"B00OI6NQUI\",\n","                \"title\": \"wall frames dcor kg set command to holds of pk free and for small hanging damage picture adhesive strips paper white pictures up\",\n","                \"price\": 7.89,\n","                \"label\": 57935\n","            },\n","            {\n","                \"id\": \"B09HLDN8W1\",\n","                \"title\": \"hooks pack fairy decorations command of cl value free and for small clips clear little decorating damage hanging transparent lights adhesive strips <unk> sioc\",\n","                \"price\": 6.49,\n","                \"label\": 359096\n","            },\n","            {\n","                \"id\": \"B07H54NZ3K\",\n","                \"title\": \"hanging ph picture metal strips na white small medium large assorted command\",\n","                \"price\": 25.98,\n","                \"label\": 139532\n","            }\n","        ],\n","        \"length\": 5\n","    }\n","]\n","1182181\n"]}]},{"cell_type":"markdown","source":["## Transform the sequences"],"metadata":{"id":"2AS2z9gIRzCl"}},{"cell_type":"code","source":["# def transform_the_seq(seqs):\n","#     return [ast.literal_eval(seq) for seq in seqs]\n","\n","# transformed_seq = transform_the_seq(sequences)"],"metadata":{"id":"hT2AGfgGR53n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Split into train, val, and test"],"metadata":{"id":"HhXD-tLTSBR-"}},{"cell_type":"code","source":["# # pick a random element\n","# transformed_seq = np.array(transformed_seq, dtype=object)  # Ensure it's an array\n","\n","# train_sequences, test_sequences = train_test_split(transformed_seq, test_size=0.1, random_state=42)\n","# test_sequences, val_sequences = train_test_split(test_sequences, test_size=0.5, random_state=42)\n","# print(len(train_sequences), len(val_sequences), len(test_sequences))\n","# np.random.choice(train_sequences)  # Pick an index  #"],"metadata":{"id":"Nf2tNVeRSDsJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_sequences, test_sequences = train_test_split(sequences, test_size=0.1, random_state=42)\n","test_sequences, val_sequences = train_test_split(test_sequences, test_size=0.5, random_state=42)\n","print(len(train_sequences), len(val_sequences), len(test_sequences))\n","train_sequences[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g-HoPsvgeYUA","executionInfo":{"status":"ok","timestamp":1746789573500,"user_tz":-420,"elapsed":360,"user":{"displayName":"18221083 Nazhif Haidar Putra Wibowo","userId":"14295694113135502399"}},"outputId":"cf349c7f-ec6f-46a0-d464-fd10e7f6e8ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1063962 59110 59109\n"]},{"output_type":"execute_result","data":{"text/plain":["{'session_id': 303482,\n"," 'sequence': [{'id': 'B00GMMDUIY',\n","   'title': 'table small wood xx ikea lack beige coffee',\n","   'price': 19.93,\n","   'label': 48292},\n","  {'id': 'B0822FLX45',\n","   'title': 'frame rustic songmics high vasagle assembly lbtx brown rectangular and cm narrow steel pub dining table industrial easy black bar kitchen alloy',\n","   'price': 12.99,\n","   'label': 199663},\n","  {'id': 'B07V22FSNQ',\n","   'title': 'frame rustic vasagle brown and living cm people steel for heavy style dining table industrial room black duty kdtx kitchen alloy <unk> metal',\n","   'price': 12.99,\n","   'label': 175537}],\n"," 'length': 3}"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["# Modelling"],"metadata":{"id":"_ugGo_H-SPBP"}},{"cell_type":"markdown","source":["### Model and Data Pipeline Definition"],"metadata":{"id":"Us21__tr4il4"}},{"cell_type":"code","source":["import gc\n","import psutil\n","import time\n","\n","MAX_VOCABS = {\n","    \"title\": 100000,\n","}\n","\n","# Download the nltk tokenizers with better error handling\n","def setup_nltk():\n","    try:\n","        # Try to find if punkt is already downloaded\n","        nltk.data.find('tokenizers/punkt')\n","        print(\"NLTK punkt tokenizer already downloaded\")\n","    except LookupError:\n","        try:\n","            # Try the punkt_tab first\n","            nltk.download('punkt_tab')\n","            print(\"Downloaded punkt_tab tokenizer\")\n","        except Exception:\n","            # Fall back to regular punkt\n","            nltk.download('punkt')\n","            print(\"Downloaded punkt tokenizer\")\n","\n","setup_nltk()\n","\n","feature_vocabs = defaultdict(dict)  # {feature: {token: index}}\n","feature_max_lengths = defaultdict(int)  # {feature: max_observed_sequence_length}\n","vocabs_built = False\n","\n","class SessionDataset(Dataset):\n","\n","    def __init__(self, sequences, dataset_path, max_vocabs=None, build_vocab=False):\n","        global feature_vocabs, feature_max_lengths, vocabs_built\n","        super(SessionDataset, self).__init__()\n","\n","        # # load if it exists\n","        # if os.path.exists(f\"{dataset_path}.pt\"):\n","        #     self.load(dataset_path)\n","        #     return\n","\n","        self.sequences = sequences\n","        self.max_vocabs = max_vocabs if max_vocabs is not None else MAX_VOCABS\n","\n","        # Build vocabularies if needed\n","        if build_vocab or not vocabs_built:\n","            self.build_feature_vocabs(sequences)\n","            vocabs_built = True\n","\n","        # Process and transform all sequences\n","        self.processed_sequences = []\n","        for sequence in tqdm(sequences, desc=\"Processing sequences\"):\n","            processed_items = []\n","            for item in sequence[\"sequence\"]:\n","                processed_item = {\n","                    \"id\": item.get(\"label\", -1),  # Default to -1 if ID not found\n","                    \"price\": np.float32(item.get(\"price\", 0.0)),  # Convert price to float32\n","                    \"length\": sequence[\"length\"]\n","                }\n","\n","                # Process text features (title, brand, color)\n","                for feature in self.max_vocabs.keys():\n","                    processed_item[feature] = self.numericalize_feature(item.get(feature, \"\"), feature)\n","\n","                processed_items.append(processed_item)\n","\n","            self.processed_sequences.append({\n","                \"session_id\": sequence.get(\"session_id\", -1),\n","                \"sequence\": processed_items\n","            })\n","\n","        # save the dataset\n","        # self.save(dataset_path)\n","\n","    def build_feature_vocabs(self, sequences):\n","        global feature_vocabs, feature_max_lengths\n","        feature_counts = defaultdict(Counter)\n","        # First pass: compute max sequence lengths and token frequencies\n","        for session in tqdm(sequences, desc=\"Building vocabularies\"):\n","            for item in session[\"sequence\"]:  # Include all items in the sequence\n","                for feature in feature_vocabs.keys() or MAX_VOCABS.keys():\n","                    text = item.get(feature, \"\")\n","                    tokens = self._tokenize_text(text)\n","\n","                    # Update max sequence length for the feature\n","                    feature_max_lengths[feature] = max(\n","                        feature_max_lengths[feature], len(tokens))\n","\n","                    # Update token frequencies\n","                    feature_counts[feature].update(tokens)\n","\n","        # Build vocab for each feature (capped at max_vocabs)\n","        for feature in MAX_VOCABS.keys():\n","            max_size = MAX_VOCABS[feature] - 1  # Reserve index 0 for <unk>\n","            tokens = [token for token, _ in feature_counts[feature].most_common(max_size)]\n","            feature_vocabs[feature] = {'<unk>': 0}\n","            feature_vocabs[feature].update({token: i+1 for i, token in enumerate(tokens)})\n","\n","    def _tokenize_text(self, text):\n","        \"\"\"Helper method to tokenize text consistently\"\"\"\n","        if text is None:\n","            return []\n","\n","        if isinstance(text, (int, float)):\n","            text = str(text)\n","\n","        cleaned_text = re.sub(r'[^\\w\\s]', '', text.lower().strip())\n","        return word_tokenize(cleaned_text)\n","\n","    def numericalize_feature(self, text, feature):\n","        \"\"\"Convert text to a sequence of integers based on the vocabulary\"\"\"\n","        global feature_vocabs, feature_max_lengths\n","        tokens = self._tokenize_text(text)\n","\n","        # Convert tokens to indices\n","        indices = [feature_vocabs[feature].get(token, 0) for token in tokens]\n","\n","        # Truncate/pad to observed max length for this feature\n","        max_len = feature_max_lengths[feature]\n","        if len(indices) > max_len:\n","            indices = indices[:max_len]\n","        else:\n","            indices += [0] * (max_len - len(indices))\n","\n","        return torch.tensor(indices, dtype=torch.long)\n","\n","    def save(self, path):\n","        \"\"\"\n","        Memory-efficient saving of processed sequences.\n","        Uses chunking to avoid memory explosion.\n","        \"\"\"\n","\n","        # Use a more efficient format with compression\n","        save_path = f\"{path}.pt\"\n","\n","        # Save in chunks to reduce memory usage\n","        chunk_size = 1000  # Adjust based on your dataset size and available memory\n","        num_chunks = (len(self.processed_sequences) + chunk_size - 1) // chunk_size\n","\n","        print(f\"Starting to save dataset with {len(self.processed_sequences)} sequences in {num_chunks} chunks\")\n","        initial_memory = psutil.Process().memory_info().rss / (1024 * 1024)\n","        print(f\"Initial memory usage: {initial_memory:.2f} MB\")\n","\n","        # Create a file object that supports chunking\n","        with open(save_path, 'wb') as f:\n","            # First save the number of chunks\n","            torch.save(num_chunks, f)\n","\n","            # Save each chunk separately with progress bar\n","            for i in tqdm(range(num_chunks), desc=\"Saving dataset chunks\", unit=\"chunk\"):\n","                start_idx = i * chunk_size\n","                end_idx = min((i + 1) * chunk_size, len(self.processed_sequences))\n","                chunk = self.processed_sequences[start_idx:end_idx]\n","\n","                # Explicitly detach tensors from computation graph to save memory\n","                detached_chunk = []\n","                for seq in chunk:\n","                    detached_seq = {\n","                        \"session_id\": seq[\"session_id\"],\n","                        \"sequence\": []\n","                    }\n","                    for item in seq[\"sequence\"]:\n","                        detached_item = {}\n","                        for key, value in item.items():\n","                            if isinstance(value, torch.Tensor):\n","                                detached_item[key] = value.detach().cpu()\n","                            else:\n","                                detached_item[key] = value\n","                        detached_seq[\"sequence\"].append(detached_item)\n","                    detached_chunk.append(detached_seq)\n","\n","                # Save chunk and clear from memory\n","                torch.save(detached_chunk, f)\n","\n","                # Force garbage collection to free memory\n","                gc.collect()\n","\n","                # Report memory usage periodically\n","                if i % 5 == 0 or i == num_chunks - 1:\n","                    current_memory = psutil.Process().memory_info().rss / (1024 * 1024)\n","                    print(f\"Memory usage after chunk {i+1}/{num_chunks}: {current_memory:.2f} MB\")\n","\n","            final_memory = psutil.Process().memory_info().rss / (1024 * 1024)\n","            print(f\"Dataset saved in {num_chunks} chunks to {save_path}\")\n","            print(f\"Memory change during save: {final_memory - initial_memory:.2f} MB\")\n","\n","    def load(self, path):\n","        \"\"\"\n","        Memory-efficient loading of processed sequences.\n","        Loads chunks sequentially to avoid memory explosion.\n","        \"\"\"\n","\n","        load_path = f\"{path}.pt\"\n","        self.processed_sequences = []\n","\n","        start_time = time.time()\n","        initial_memory = psutil.Process().memory_info().rss / (1024 * 1024)\n","        print(f\"Initial memory usage: {initial_memory:.2f} MB\")\n","\n","        try:\n","            with open(load_path, 'rb') as f:\n","                # First load the number of chunks\n","                num_chunks = torch.load(f)\n","                print(f\"Loading dataset with {num_chunks} chunks from {load_path}\")\n","\n","                # Load each chunk with progress bar\n","                for i in tqdm(range(num_chunks), desc=\"Loading dataset chunks\", unit=\"chunk\"):\n","                    chunk_start = time.time()\n","                    chunk = torch.load(f)\n","                    self.processed_sequences.extend(chunk)\n","\n","                    # Force garbage collection after each chunk\n","                    gc.collect()\n","\n","                    # Report memory and time usage periodically\n","                    if i % 5 == 0 or i == num_chunks - 1:\n","                        current_memory = psutil.Process().memory_info().rss / (1024 * 1024)\n","                        chunk_time = time.time() - chunk_start\n","                        print(f\"Chunk {i+1}/{num_chunks} loaded in {chunk_time:.2f}s. Memory usage: {current_memory:.2f} MB\")\n","\n","                total_time = time.time() - start_time\n","                final_memory = psutil.Process().memory_info().rss / (1024 * 1024)\n","                print(f\"Dataset loaded successfully from {load_path} ({len(self.processed_sequences)} sequences)\")\n","                print(f\"Total loading time: {total_time:.2f}s\")\n","                print(f\"Memory change during load: {final_memory - initial_memory:.2f} MB\")\n","        except Exception as e:\n","            print(f\"Error loading dataset: {e}\")\n","            # Initialize empty list if load fails\n","            self.processed_sequences = []\n","\n","    def __len__(self):\n","        return len(self.processed_sequences)\n","\n","    def __getitem__(self, index):\n","        \"\"\"\n","        Return map-style dataset with:\n","        - \"id\": item id\n","        - \"title\": tokenized and numericalized title\n","        - \"price\": price as float32\n","        \"\"\"\n","        # Return the processed sequence at the given index\n","        return self.processed_sequences[index]\n","\n","def collate_fn(batch):\n","    \"\"\"\n","    Collate function to create batches from multiple sessions.\n","\n","    For each session:\n","    - Input: All items except the last one (sequence[:n-1])\n","    - Target: The last item in the sequence (sequence[n-1])\n","    - Length: Length of input sequence (n-1)\n","\n","    Args:\n","        batch: List of session dictionaries with 'sequence' field\n","\n","    Returns:\n","        tuple: (batched_inputs, batched_targets, sequence_lengths)\n","            - batched_inputs: Dictionary of tensors for each feature\n","            - batched_targets: Tensor of target item IDs\n","            - sequence_lengths: Tensor of input sequence lengths\n","    \"\"\"\n","    # Extract sequences from batch\n","    batch_inputs = []\n","    batch_targets = []\n","    sequence_lengths = []\n","\n","    for session in batch:\n","        sequence = session[\"sequence\"]\n","        # Only process sequences with at least 2 items\n","        if len(sequence) > 1:\n","            # Prepare inputs (all but last item)\n","            session_inputs = {\n","                \"id\": [],\n","                \"title\": [],\n","                \"price\": []\n","            }\n","            sequence_length = len(sequence)-1\n","\n","            # Extract features for all items except the last one (inputs)\n","            for item in sequence[:-1]:\n","                session_inputs[\"id\"].append(item[\"id\"])\n","                session_inputs[\"title\"].append(item[\"title\"])\n","                session_inputs[\"price\"].append(item[\"price\"])\n","\n","            # Get the last item as the target\n","            target_item = sequence[-1]\n","            target_id = target_item[\"id\"]\n","\n","            # Convert lists to tensors\n","            valid_session = True\n","            for key in session_inputs:\n","                if not session_inputs[key]:  # Skip empty sequences\n","                    valid_session = False\n","                    break\n","\n","                # Convert to appropriate tensor types\n","                if key == \"price\":\n","                    # Handle price as a 1D tensor and reshape to [seq_len, 1]\n","                    session_inputs[key] = torch.tensor(session_inputs[key], dtype=torch.float).view(-1, 1)\n","                elif key == \"id\":\n","                    # Convert IDs to long tensor\n","                    session_inputs[key] = torch.tensor(session_inputs[key], dtype=torch.long)\n","                elif key == \"title\":\n","                    # For title tensors which may already be tensors with multiple dimensions\n","                    try:\n","                        session_inputs[key] = torch.stack(session_inputs[key])\n","                    except (RuntimeError, TypeError):\n","                        try:\n","                            # If we can't stack, they might not be tensors yet\n","                            tensors = []\n","                            for item in session_inputs[key]:\n","                                if isinstance(item, torch.Tensor):\n","                                    tensors.append(item)\n","                                else:\n","                                    # Try converting to tensor if not already\n","                                    tensors.append(torch.tensor(item, dtype=torch.long))\n","                            session_inputs[key] = torch.stack(tensors)\n","                        except (RuntimeError, TypeError):\n","                            valid_session = False\n","                            break\n","                else:\n","                    # For other features\n","                    try:\n","                        # First check if items are already tensors\n","                        if isinstance(session_inputs[key][0], torch.Tensor):\n","                            session_inputs[key] = torch.stack(session_inputs[key])\n","                        else:\n","                            # If not tensors, convert to long tensors\n","                            session_inputs[key] = torch.tensor(session_inputs[key], dtype=torch.long)\n","                    except (RuntimeError, TypeError):\n","                        # Handle case where items can't be stacked or converted\n","                        valid_session = False\n","                        break\n","\n","            if valid_session:\n","                batch_inputs.append(session_inputs)\n","                batch_targets.append(target_id)\n","                sequence_lengths.append(sequence_length)\n","\n","    # If no valid sequences were found, return None\n","    if not batch_inputs:\n","        return None, None, None\n","\n","    # Pad sequences to the same length within the batch\n","    max_len = max(len(inputs[\"id\"]) for inputs in batch_inputs)\n","\n","    for i in range(len(batch_inputs)):\n","        for key in batch_inputs[i]:\n","            if key == \"price\":\n","                # Pad price tensor\n","                current_len = batch_inputs[i][key].size(0)\n","                if current_len < max_len:\n","                    padding = torch.zeros(max_len - current_len, 1, dtype=torch.float)\n","                    batch_inputs[i][key] = torch.cat([batch_inputs[i][key], padding], dim=0)\n","            else:\n","                # Pad ID and text feature tensors\n","                current_len = batch_inputs[i][key].size(0)\n","                if current_len < max_len:\n","                    padding = torch.zeros(max_len - current_len, *batch_inputs[i][key].size()[1:],\n","                                         dtype=batch_inputs[i][key].dtype)\n","                    batch_inputs[i][key] = torch.cat([batch_inputs[i][key], padding], dim=0)\n","\n","    # Stack all batch data\n","    batched_inputs = {\n","        key: torch.stack([inputs[key] for inputs in batch_inputs])\n","        for key in batch_inputs[0]\n","    }\n","\n","    # Convert targets to tensor\n","    batched_targets = torch.tensor(batch_targets, dtype=torch.long)\n","\n","    # Convert sequence lengths to tensor\n","    sequence_lengths = torch.tensor(sequence_lengths, dtype=torch.long)\n","\n","    return batched_inputs, batched_targets, sequence_lengths\n","\n","\n","class FeatureEmbedding(nn.Module):\n","    def __init__(self,\n","                 num_embeddings,\n","                 title_embedding_dim,\n","                 price_out_dim,\n","                 output_size,\n","                 ):\n","        super(FeatureEmbedding, self).__init__()\n","        self.title_embedding = nn.Embedding(num_embeddings[\"title\"], title_embedding_dim)\n","        self.price_layer = nn.Linear(1, price_out_dim)\n","        self.output_size = output_size\n","\n","        # Pool text embeddings across token dimension\n","        self.title_pool = nn.AdaptiveAvgPool1d(1)\n","\n","        # Final projection layer\n","        self.linear = nn.Linear(title_embedding_dim + price_out_dim, output_size)\n","\n","    def forward(self, title, price):\n","        # Get original batch and sequence dimensions\n","        batch_size, seq_len = title.size(0), title.size(1)\n","\n","        # Flatten the batch and sequence dimensions for processing\n","        flat_title = title.view(-1, title.size(-1))  # [batch*seq, title_seq_len]\n","        flat_price = price.view(-1, 1)  # [batch*seq, 1]\n","\n","        # Process text features through embeddings\n","        title_emb = self.title_embedding(flat_title)  # [batch*seq, title_seq_len, title_emb_dim]\n","\n","        # Pool across token dimension for each feature\n","        # Transpose to get shape [batch*seq, emb_dim, seq_len] for pooling\n","        title_emb = title_emb.transpose(1, 2)  # [batch*seq, title_emb_dim, title_seq_len]\n","\n","        # Apply pooling\n","        title_emb = self.title_pool(title_emb).squeeze(-1)  # [batch*seq, title_emb_dim]\n","\n","        # Process price\n","        price_emb = self.price_layer(flat_price)  # [batch*seq, price_out_dim]\n","\n","        # Concatenate all features\n","        all_emb = torch.cat([title_emb, price_emb], dim=-1)  # [batch*seq, all_emb_dim]\n","\n","        # Final projection\n","        output = self.linear(all_emb)  # [batch*seq, output_size]\n","\n","        # Reshape back to [batch, seq, output_size]\n","        output = output.view(batch_size, seq_len, -1)\n","\n","        return output\n","\n","\n","class NARM(nn.Module):\n","    def __init__(self, n_items, hidden_size, embedding_dim, batch_size,\n","                 num_layers=1, feature_embedding_args=None, **kwargs):\n","        super().__init__()\n","        self.n_items = n_items + 1  # +1 for padding index\n","        self.hidden_size = hidden_size\n","        self.embedding_dim = embedding_dim\n","\n","        # Initialize device right away\n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","        # Embedding layers\n","        self.embedding = nn.Embedding(self.n_items, embedding_dim, padding_idx=0).to(self.device)\n","\n","        # Feature embedding\n","        self.feature_embedding = None\n","        if feature_embedding_args:\n","            self.feature_embedding = FeatureEmbedding(\n","                num_embeddings=feature_embedding_args[\"num_embeddings\"],\n","                title_embedding_dim=feature_embedding_args[\"title_embedding_dim\"],\n","                price_out_dim=feature_embedding_args[\"price_out_dim\"],\n","                output_size=embedding_dim\n","            ).to(self.device)\n","\n","        # GRU and attention\n","        self.gru = nn.GRU(embedding_dim, hidden_size, num_layers, batch_first=True).to(self.device)\n","        self.attn_W1 = nn.Linear(hidden_size, hidden_size).to(self.device)\n","        self.attn_W2 = nn.Linear(hidden_size, hidden_size).to(self.device)\n","        self.attn_v = nn.Linear(hidden_size, 1).to(self.device)\n","\n","        # Scoring\n","        self.wh = nn.Linear(2*hidden_size, hidden_size).to(self.device)\n","        self.wi = nn.Linear(embedding_dim, hidden_size).to(self.device)\n","\n","        self.dropout = nn.Dropout(0.5).to(self.device)\n","\n","    def forward(self, inputs, lengths):\n","        # Ensure all inputs are on the correct device\n","        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n","        lengths = lengths.to(self.device)\n","\n","        # Embedding\n","        item_emb = self.embedding(inputs[\"id\"])\n","\n","        # Feature fusion\n","        if self.feature_embedding:\n","            feat_emb = self.feature_embedding(\n","                inputs[\"title\"],\n","                inputs[\"price\"]\n","            )\n","            item_emb = item_emb + feat_emb\n","\n","        # GRU processing\n","        packed = pack_padded_sequence(item_emb, lengths.cpu(), batch_first=True, enforce_sorted=False)\n","        gru_out, hidden = self.gru(packed)\n","        gru_out, _ = pad_packed_sequence(gru_out, batch_first=True)\n","\n","        # Attention mechanism\n","        h_t = hidden[-1]\n","        W1_h = self.attn_W1(gru_out)\n","        W2_ht = self.attn_W2(h_t).unsqueeze(1)\n","        attn_scores = self.attn_v(torch.tanh(W1_h + W2_ht)).squeeze(2)\n","\n","        # Apply mask\n","        mask = (inputs[\"id\"] != 0).float()\n","        attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n","        attn_weights = F.softmax(attn_scores, dim=1)\n","\n","        # Context vectors\n","        c_local = torch.bmm(attn_weights.unsqueeze(1), gru_out).squeeze(1)\n","        c_global = h_t\n","        c = torch.cat([c_global, c_local], dim=1)\n","        c = self.dropout(c)\n","\n","        # Scoring\n","        all_items = self.embedding.weight[1:]  # Exclude padding\n","        scores = torch.matmul(self.wh(c), self.wi(all_items).t())\n","\n","        return scores\n","\n","    def init_hidden(self, batch_size):\n","        return torch.zeros(self.num_layers, batch_size, self.hidden_size, device=self.device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yqm8hVRLSP_C","executionInfo":{"status":"ok","timestamp":1746789573703,"user_tz":-420,"elapsed":127,"user":{"displayName":"18221083 Nazhif Haidar Putra Wibowo","userId":"14295694113135502399"}},"outputId":"d5bb166e-50ea-4501-a3c3-a91df6288cc7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloaded punkt_tab tokenizer\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["## Define Training Loop"],"metadata":{"id":"n8dskJMjBDdq"}},{"cell_type":"code","source":["import mlflow\n","import mlflow.pytorch\n","import copy\n","import json\n","from datetime import datetime\n","\n","MODEL_SAVE_PATH = \"/content/drive/My Drive/TA/Implementasi/NARM\"\n","os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n","\n","def save_checkpoint(model, optimizer, epoch, loss, model_name, metrics=None):\n","    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    checkpoint_path = os.path.join(MODEL_SAVE_PATH, f\"{model_name}.pt\")\n","\n","    # Create checkpoint dictionary with all necessary information\n","    checkpoint = {\n","        'epoch': epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'loss': loss,\n","    }\n","\n","    # Add metrics if provided\n","    if metrics is not None:\n","        checkpoint['metrics'] = metrics\n","\n","    # Save the checkpoint\n","    torch.save(checkpoint, checkpoint_path)\n","    print(f\"Model saved to {checkpoint_path}\")\n","\n","    return checkpoint_path\n","\n","def load_checkpoint(model, optimizer, checkpoint_path):\n","    checkpoint = torch.load(checkpoint_path)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    epoch = checkpoint['epoch']\n","    loss = checkpoint['loss']\n","\n","    metrics = checkpoint.get('metrics', None)\n","\n","    print(f\"Loaded checkpoint from epoch {epoch} with loss: {loss:.4f}\")\n","\n","    return model, optimizer, epoch, loss, metrics\n","\n","def train(model, epochs, train_loader, val_loader=None, checkpoint_path=None, save_every=1,\n","          model_name=\"NARM\", use_mlflow=True, run_name=None, **kwargs):\n","    lr = kwargs.get(\"learning_rate\", 0.001)\n","    patience = kwargs.get(\"patience\", 5)  # For early stopping\n","\n","    # Setup optimizer and loss\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","    criterion = nn.CrossEntropyLoss()\n","    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","\n","    # Initialize tracking variables\n","    start_epoch = 0\n","    losses = []\n","    val_losses = []\n","    train_accuracies = []\n","    val_accuracies = []\n","    best_val_acc = 0.0\n","    best_model_state = None\n","    patience_counter = 0\n","\n","    # Load checkpoint if provided\n","    if checkpoint_path and os.path.exists(checkpoint_path):\n","        model, optimizer, start_epoch, _, _ = load_checkpoint(model, optimizer, checkpoint_path)\n","        start_epoch += 1  # Start from the next epoch\n","\n","    # Set up MLflow if requested\n","    if use_mlflow:\n","        if run_name is None:\n","            run_name = f\"{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n","\n","        mlflow.set_experiment(f\"NARM_Training_{model_name}\")\n","        mlflow.start_run(run_name=run_name)\n","\n","        # Log parameters\n","        mlflow.log_params({\n","            \"learning_rate\": lr,\n","            \"model_name\": model_name,\n","            \"batch_size\": train_loader.batch_size if hasattr(train_loader, 'batch_size') else 'unknown',\n","            \"epochs\": epochs,\n","            \"patience\": patience,\n","            **kwargs\n","        })\n","\n","    try:\n","        for epoch in range(start_epoch, epochs + start_epoch):\n","            # Training phase\n","            model.train()\n","            epoch_losses = []\n","            correct = 0\n","            total = 0\n","\n","            progress_bar = tqdm(train_loader, total=len(train_loader), desc=f\"Epoch {epoch+1}/{epochs+start_epoch}\")\n","            for i, batch in enumerate(progress_bar):\n","                # Check if batch contains data\n","                if batch[0] is None:\n","                    continue\n","\n","                inputs, targets, lengths = batch\n","\n","                # Move data to model's device\n","                inputs = {k: v.to(model.device) for k, v in inputs.items()} if isinstance(inputs, dict) else inputs.to(model.device)\n","                targets = targets.to(model.device)\n","                lengths = lengths.to(model.device)\n","\n","                # Forward pass\n","                optimizer.zero_grad()\n","                scores = model(inputs, lengths)\n","                loss = criterion(scores, targets)\n","\n","                # Backward pass\n","                loss.backward()\n","                optimizer.step()\n","\n","                # Track loss and accuracy\n","                loss_val = loss.item()\n","                epoch_losses.append(loss_val)\n","\n","                # Calculate training accuracy\n","                _, predicted = torch.max(scores.data, 1)\n","                total += targets.size(0)\n","                correct += (predicted == targets).sum().item()\n","\n","                progress_bar.set_postfix({'loss': f\"{loss_val:.4f}\", 'acc': f\"{correct/total:.4f}\"})\n","\n","            # Calculate average epoch loss and accuracy\n","            avg_epoch_loss = sum(epoch_losses) / len(epoch_losses) if epoch_losses else float('inf')\n","            epoch_accuracy = correct / total if total > 0 else 0\n","            losses.append(avg_epoch_loss)\n","            train_accuracies.append(epoch_accuracy)\n","\n","            # Update learning rate scheduler\n","            scheduler.step()\n","\n","            # Validation phase if val_loader provided\n","            if val_loader:\n","                res, current_val_loss = test(model, val_loader, log_results=False)\n","                val_acc = res.overall.accuracy\n","                val_losses.append(current_val_loss)\n","                val_accuracies.append(val_acc)\n","\n","                # Log training progress\n","                log_line = (f\"Epoch {epoch+1}/{epochs+start_epoch}, \"\n","                      f\"Train Loss: {avg_epoch_loss:.4f}, \"\n","                      f\"Train Acc: {epoch_accuracy:.4f}, \"\n","                      f\"Val Loss: {current_val_loss:.4f}, \"\n","                      f\"Val Acc: {val_acc:.4f}\")\n","                print(\"\\n\" + log_line)\n","\n","                # Write to log file\n","                with open(os.path.join(MODEL_SAVE_PATH, f\"{model_name}_training_log.txt\"), \"a\") as f:\n","                    f.write(log_line + \"\\n\")\n","\n","                # Log to MLflow\n","                if use_mlflow:\n","                    mlflow.log_metrics({\n","                        \"train_loss\": avg_epoch_loss,\n","                        \"train_acc\": epoch_accuracy,\n","                        \"val_loss\": current_val_loss,\n","                        \"val_acc\": val_acc,\n","                    }, step=epoch)\n","\n","                # Early stopping check\n","                if val_acc > best_val_acc:\n","                    best_val_acc = val_acc\n","                    best_model_state = copy.deepcopy(model.state_dict())\n","                    patience_counter = 0\n","\n","                    # Save best model\n","                    best_model_path = os.path.join(MODEL_SAVE_PATH, f\"{model_name}_best.pt\")\n","                    torch.save({\n","                        'epoch': epoch,\n","                        'model_state_dict': model.state_dict(),\n","                        'optimizer_state_dict': optimizer.state_dict(),\n","                        'loss': avg_epoch_loss,\n","                        'val_loss': current_val_loss,\n","                        'metrics': {'acc': val_acc}\n","                    }, best_model_path)\n","\n","                    if use_mlflow:\n","                        mlflow.log_artifact(best_model_path)\n","                else:\n","                    patience_counter += 1\n","                    if patience_counter >= patience:\n","                        print(f\"Early stopping triggered after {epoch+1} epochs\")\n","                        # Restore best model\n","                        model.load_state_dict(best_model_state)\n","                        break\n","            else:\n","                log_line = f\"Epoch {epoch+1}/{epochs+start_epoch}, Train Loss: {avg_epoch_loss:.4f}, Train Acc: {epoch_accuracy:.4f}\"\n","                print(\"\\n\" + log_line)\n","                with open(os.path.join(MODEL_SAVE_PATH, f\"{model_name}_training_log.txt\"), \"a\") as f:\n","                    f.write(log_line + \"\\n\")\n","\n","                if use_mlflow:\n","                    mlflow.log_metrics({\n","                        \"train_loss\": avg_epoch_loss,\n","                        \"train_acc\": epoch_accuracy\n","                    }, step=epoch)\n","\n","            # Save checkpoint if needed\n","            if (epoch + 1) % save_every == 0:\n","                metrics = {'acc': val_acc} if val_loader else {'train_acc': epoch_accuracy}\n","                checkpoint_path = save_checkpoint(\n","                    model, optimizer, epoch + 1, avg_epoch_loss, model_name, metrics\n","                )\n","\n","                # Log to MLflow\n","                if use_mlflow:\n","                    mlflow.log_artifact(checkpoint_path)\n","\n","        # Save the final model\n","        final_checkpoint_path = save_checkpoint(\n","            model, optimizer, epoch + 1, avg_epoch_loss, f\"{model_name}_final\"\n","        )\n","\n","        # Log final model to MLflow\n","        if use_mlflow:\n","            mlflow.pytorch.log_model(model, \"final_model\")\n","            mlflow.log_artifact(final_checkpoint_path)\n","\n","            # Log training history as JSON\n","            history = {\n","                \"train_losses\": losses,\n","                \"val_losses\": val_losses if val_loader else [],\n","                \"train_accuracies\": train_accuracies,\n","                \"val_accuracies\": val_accuracies if val_loader else []\n","            }\n","            history_path = os.path.join(MODEL_SAVE_PATH, f\"{model_name}_history.json\")\n","            with open(history_path, 'w') as f:\n","                json.dump(history, f)\n","            mlflow.log_artifact(history_path)\n","\n","            # Save training history to CSV\n","            history_df = pd.DataFrame({\n","                'epoch': range(1, len(losses)+1),\n","                'train_loss': losses,\n","                'val_loss': val_losses if val_loader else [None]*len(losses),\n","                'train_acc': train_accuracies,\n","                'val_acc': val_accuracies if val_loader else [None]*len(losses)\n","            })\n","            csv_path = os.path.join(MODEL_SAVE_PATH, f\"{model_name}_history.csv\")\n","            history_df.to_csv(csv_path, index=False)\n","            mlflow.log_artifact(csv_path)\n","\n","            # Plot and save training curves\n","            plt.figure(figsize=(12, 6))\n","\n","            # Plot losses\n","            plt.subplot(1, 2, 1)\n","            plt.plot(history_df['epoch'], history_df['train_loss'], label='Train Loss')\n","            if val_loader:\n","                plt.plot(history_df['epoch'], history_df['val_loss'], label='Val Loss')\n","            plt.xlabel('Epoch')\n","            plt.ylabel('Loss')\n","            plt.title('Training and Validation Loss')\n","            plt.legend()\n","\n","            # Plot accuracies\n","            plt.subplot(1, 2, 2)\n","            plt.plot(history_df['epoch'], history_df['train_acc'], label='Train Acc')\n","            if val_loader:\n","                plt.plot(history_df['epoch'], history_df['val_acc'], label='Val Acc')\n","            plt.xlabel('Epoch')\n","            plt.ylabel('Accuracy')\n","            plt.title('Training and Validation Accuracy')\n","            plt.legend()\n","\n","            plt.tight_layout()\n","            plot_path = os.path.join(MODEL_SAVE_PATH, f\"{model_name}_training_curves.png\")\n","            plt.savefig(plot_path)\n","            plt.close()\n","\n","            mlflow.log_artifact(plot_path)\n","\n","    finally:\n","        # End MLflow run\n","        if use_mlflow:\n","            mlflow.end_run()\n","\n","    # If we have a validation set and used early stopping, make sure we return the best model\n","    if val_loader and best_model_state is not None:\n","        model.load_state_dict(best_model_state)\n","\n","    return model, losses, val_losses if val_loader else None\n","\n","def test(model, test_loader, k=10, log_results=True, validation=True):\n","    \"\"\"\n","    Test the model and calculate metrics\n","\n","    Args:\n","        model: The model to test\n","        test_loader: DataLoader for test data\n","        k: Value for top-k metrics calculation\n","        log_results: Whether to print results\n","\n","    Returns:\n","        tuple: (MRR@k, Hit@k, average_loss)\n","    \"\"\"\n","    model.eval()\n","    criterion = nn.CrossEntropyLoss(reduction='sum')  # Sum reduction for accurate loss calculation\n","\n","    total_loss = 0\n","    # Overall session\n","    mrr_at_k = 0\n","    hit_at_k = 0\n","    accuracy = 0\n","    total_samples = 0\n","\n","    # Define classification threshold\n","    short = 4\n","    medium = 10\n","\n","    # short\n","    mrr_at_k_short = 0\n","    hit_at_k_short = 0\n","    accuracy_short = 0\n","    total_samples_short = 0\n","\n","    # medium\n","    mrr_at_k_medium = 0\n","    hit_at_k_medium = 0\n","    accuracy_medium = 0\n","    total_samples_medium = 0\n","\n","    # long\n","    mrr_at_k_long = 0\n","    hit_at_k_long = 0\n","    accuracy_long = 0\n","    total_samples_long = 0\n","\n","\n","\n","    with torch.no_grad():  # No gradient computation needed for testing\n","        for batch in tqdm(test_loader, total=len(test_loader), desc=\"Testing\"):\n","            # Check if batch contains data\n","            if batch[0] is None:\n","                continue\n","\n","            inputs, targets, lengths = batch\n","\n","            # Move data to model's device\n","            inputs = {k: v.to(model.device) for k, v in inputs.items()} if isinstance(inputs, dict) else inputs.to(model.device)\n","            targets = targets.to(model.device)\n","            lengths = lengths.to(model.device)\n","\n","            # Forward pass\n","            scores = model(inputs, lengths)\n","            loss = criterion(scores, targets)\n","            total_loss += loss.item()\n","\n","            # Convert to numpy for metrics calculation\n","            scores_np = scores.cpu().numpy()\n","            targets_np = targets.cpu().numpy()\n","\n","            batch_size = scores_np.shape[0]\n","            total_samples += batch_size\n","            total_samples_short += (lengths < short).sum().item()\n","            total_samples_medium += ((lengths >= short) & (lengths < medium)).sum().item()\n","            total_samples_long += (lengths >= medium).sum().item()\n","\n","            # pick max value\n","            max_values, max_indices = torch.max(scores, dim=1)\n","            n_correct = (max_indices == targets).sum().item()\n","            n_correct_short = (max_indices[lengths < short] == targets[lengths < short]).sum().item()\n","            n_correct_medium = (max_indices[(lengths >= short) & (lengths < medium)] == targets[(lengths >= short) & (lengths < medium)]).sum().item()\n","            n_correct_long = (max_indices[lengths >= medium] == targets[lengths >= medium]).sum().item()\n","            accuracy += n_correct\n","            accuracy_short += n_correct_short\n","            accuracy_medium += n_correct_medium\n","            accuracy_long += n_correct_long\n","\n","\n","            if not validation:\n","                # Simple top-k implementation\n","                topk_values, topk_indices = torch.topk(scores, k=k, dim=1)\n","\n","                # Compare with ground truth\n","                for i in range(batch_size):\n","                    if targets[i] in topk_indices[i]:\n","                        hit_at_k += 1\n","                        # Find position (1-indexed)\n","                        pos = (topk_indices[i] == targets[i]).nonzero(as_tuple=True)[0].item() + 1\n","                        mrr_at_k += 1.0 / pos\n","\n","                        # check if session is short\n","                        if lengths[i] < short:\n","                            mrr_at_k_short += 1.0 / pos\n","                            hit_at_k_short += 1\n","                        elif lengths[i] < medium:\n","                            mrr_at_k_medium += 1.0 / pos\n","                            hit_at_k_medium += 1\n","                        else:\n","                            mrr_at_k_long += 1.0 / pos\n","                            hit_at_k_long += 1\n","\n","\n","\n","    # Calculate average metrics\n","    avg_loss = total_loss / total_samples if total_samples > 0 else float('inf')\n","    accuracy = accuracy / total_samples if total_samples > 0 else 0\n","    hit_at_k = hit_at_k / total_samples if total_samples > 0 else 0\n","    mrr_at_k = mrr_at_k / total_samples if total_samples > 0 else 0\n","\n","    # short\n","    accuracy_short = accuracy_short / total_samples_short if total_samples_short > 0 else 0\n","    hit_at_k_short = hit_at_k_short / total_samples_short if total_samples_short > 0 else 0\n","    mrr_at_k_short = mrr_at_k_short / total_samples_short\n","\n","    # medium\n","    accuracy_medium = accuracy_medium / total_samples_medium if total_samples_medium > 0 else 0\n","    hit_at_k_medium = hit_at_k_medium / total_samples_medium if total_samples_medium > 0 else 0\n","    mrr_at_k_medium = mrr_at_k_medium / total_samples_medium\n","\n","    # long\n","    accuracy_long = accuracy_long / total_samples_long if total_samples_long > 0 else 0\n","    hit_at_k_long = hit_at_k_long / total_samples_long if total_samples_long > 0 else 0\n","    mrr_at_k_long = mrr_at_k_long / total_samples_long\n","\n","    # create result dictionary\n","    short_results = {\n","        \"hit_at_k\": hit_at_k_short,\n","        \"mrr_at_k\": mrr_at_k_short,\n","        \"accuracy\": accuracy_short\n","    }\n","    medium_results = {\n","        \"hit_at_k\": hit_at_k_medium,\n","        \"mrr_at_k\": mrr_at_k_medium,\n","        \"accuracy\": accuracy_medium\n","    }\n","    long_results = {\n","        \"hit_at_k\": hit_at_k_long,\n","        \"mrr_at_k\": mrr_at_k_long,\n","        \"accuracy\": accuracy_long\n","    }\n","    overall_results = {\n","        \"hit_at_k\": hit_at_k,\n","        \"mrr_at_k\": mrr_at_k,\n","        \"accuracy\": accuracy\n","    }\n","\n","    results = {\n","        \"short\": short_results,\n","        \"medium\": medium_results,\n","        \"long\": long_results,\n","        \"overall\": overall_results\n","    }\n","\n","\n","    # scale all values to 100\n","    for key, value in results.items():\n","        for subkey, subvalue in value.items():\n","            value[subkey] = subvalue * 100\n","    # make the results dict can be viewed as object\n","    results = objectview(results)\n","\n","    if log_results:\n","        print(f\"Test Results:\")\n","        print(f\"  Loss: {avg_loss:.4f}\")\n","        print(f\"  Accuracy: {accuracy:.4f}\")\n","        if not validation:\n","            print(f\"  Hit@{k}: {hit_at_k:.4f}\")\n","            print(f\"  MRR@{k}: {mrr_at_k:.4f}\")\n","        print(f\"  Total samples: {total_samples}\")\n","\n","    return results, avg_loss\n"],"metadata":{"id":"G9DEKeDPBFcH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training and Testing"],"metadata":{"id":"MSrEGeMRrTi3"}},{"cell_type":"markdown","source":["## Model training"],"metadata":{"id":"DI9Q_GvvrXV2"}},{"cell_type":"code","source":["batch_size = 512"],"metadata":{"id":"2VMCh8LN70xK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path = PROJECT_PATH + \"/NARM/dataset\"\n","\n","train_dataset = SessionDataset(train_sequences, max_vocabs=MAX_VOCABS, dataset_path=path+\"/train\")\n","val_dataset = SessionDataset(val_sequences, max_vocabs=MAX_VOCABS, dataset_path=path + \"/val\")\n","test_dataset = SessionDataset(test_sequences, max_vocabs=MAX_VOCABS, dataset_path=path + \"/test\")\n","\n"],"metadata":{"id":"mNqgVesfrUzC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746796441489,"user_tz":-420,"elapsed":809365,"user":{"displayName":"18221083 Nazhif Haidar Putra Wibowo","userId":"14295694113135502399"}},"outputId":"e186b4f1-b052-4ec7-83bf-25643d1a7a67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing sequences: 100%|██████████| 1063962/1063962 [12:10<00:00, 1455.91it/s]\n","Processing sequences: 100%|██████████| 59110/59110 [00:38<00:00, 1521.79it/s]\n","Processing sequences: 100%|██████████| 59109/59109 [00:39<00:00, 1485.22it/s]\n"]}]},{"cell_type":"code","source":["\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"],"metadata":{"id":"h8YJYiV4GRGO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import joblib\n","\n","label_encoder = joblib.load(DATASETS_PATH + \"/product_id_encoder.joblib\")"],"metadata":{"id":"e_K3U5FmKcKu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_embeddings_feature = {\n","    \"num_embeddings\": {\n","        \"title\": MAX_VOCABS[\"title\"]\n","    },\n","    \"title_embedding_dim\": 16,\n","    \"price_out_dim\": 4\n","}\n","\n","args = {\n","    \"n_items\" : label_encoder.classes_.shape[0],\n","    \"hidden_size\" : 32,\n","    \"embedding_dim\" : 32,\n","    \"n_layers\" : 1,\n","    \"batch_size\" : batch_size,\n","    \"num_embeddings_feature\" : num_embeddings_feature,\n","}\n","\n","args = objectview(args)\n","\n","\n","model = NARM(\n","    n_items=args.n_items,\n","    hidden_size=args.hidden_size,\n","    embedding_dim=args.embedding_dim,\n","    n_layers=args.n_layers,\n","    batch_size=args.batch_size,\n","    num_embeddings_feature=num_embeddings_feature\n",")"],"metadata":{"id":"O7E8vtU1J32X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!export CUDA_LAUNCH_BLOCKING=1"],"metadata":{"id":"edmT_y5qBe_o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# train\n","best_model, losses, val_losses = train(model, 40, train_loader, val_loader, MODEL_SAVE_PATH+\"/checkpoints\")"],"metadata":{"id":"Yup9f5yJJ3cA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3ee64f60-691a-40ba-9ec6-a565ae248659","executionInfo":{"status":"ok","timestamp":1746804800751,"user_tz":-420,"elapsed":8358868,"user":{"displayName":"18221083 Nazhif Haidar Putra Wibowo","userId":"14295694113135502399"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/40: 100%|██████████| 2079/2079 [04:12<00:00,  8.22it/s, loss=12.9372, acc=0.0000]\n","Testing: 100%|██████████| 116/116 [01:31<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 1/40, Train Loss: 13.0080, Train Acc: 0.0000, Val Loss: 12.8668, Val Acc: 0.0017\n","Model saved to /content/drive/My Drive/Tugas Akhir/NARM/NARM.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/40: 100%|██████████| 2079/2079 [04:12<00:00,  8.23it/s, loss=12.4429, acc=0.0000]\n","Testing: 100%|██████████| 116/116 [01:31<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 2/40, Train Loss: 12.5612, Train Acc: 0.0000, Val Loss: 12.6806, Val Acc: 0.0118\n","Model saved to /content/drive/My Drive/Tugas Akhir/NARM/NARM.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/40: 100%|██████████| 2079/2079 [04:12<00:00,  8.25it/s, loss=12.1125, acc=0.0001]\n","Testing: 100%|██████████| 116/116 [01:31<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 3/40, Train Loss: 12.3375, Train Acc: 0.0001, Val Loss: 12.6117, Val Acc: 0.0068\n","Model saved to /content/drive/My Drive/Tugas Akhir/NARM/NARM.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/40: 100%|██████████| 2079/2079 [04:12<00:00,  8.24it/s, loss=12.1637, acc=0.0002]\n","Testing: 100%|██████████| 116/116 [01:31<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 4/40, Train Loss: 12.2130, Train Acc: 0.0002, Val Loss: 12.5698, Val Acc: 0.0423\n","Model saved to /content/drive/My Drive/Tugas Akhir/NARM/NARM.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/40: 100%|██████████| 2079/2079 [04:24<00:00,  7.86it/s, loss=12.0893, acc=0.0007]\n","Testing: 100%|██████████| 116/116 [01:33<00:00,  1.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 5/40, Train Loss: 12.0915, Train Acc: 0.0007, Val Loss: 12.5387, Val Acc: 0.1540\n","Model saved to /content/drive/My Drive/Tugas Akhir/NARM/NARM.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/40: 100%|██████████| 2079/2079 [04:15<00:00,  8.13it/s, loss=12.2383, acc=0.0014]\n","Testing: 100%|██████████| 116/116 [01:31<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 6/40, Train Loss: 11.9536, Train Acc: 0.0014, Val Loss: 12.5541, Val Acc: 0.1759\n","Model saved to /content/drive/My Drive/Tugas Akhir/NARM/NARM.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/40: 100%|██████████| 2079/2079 [04:12<00:00,  8.25it/s, loss=11.7223, acc=0.0016]\n","Testing: 100%|██████████| 116/116 [01:32<00:00,  1.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 7/40, Train Loss: 11.9346, Train Acc: 0.0016, Val Loss: 12.5560, Val Acc: 0.1979\n","Model saved to /content/drive/My Drive/Tugas Akhir/NARM/NARM.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8/40: 100%|██████████| 2079/2079 [04:14<00:00,  8.17it/s, loss=11.7277, acc=0.0018]\n","Testing: 100%|██████████| 116/116 [01:31<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 8/40, Train Loss: 11.9184, Train Acc: 0.0018, Val Loss: 12.5516, Val Acc: 0.2013\n","Model saved to /content/drive/My Drive/Tugas Akhir/NARM/NARM.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9/40: 100%|██████████| 2079/2079 [04:12<00:00,  8.24it/s, loss=11.5841, acc=0.0019]\n","Testing: 100%|██████████| 116/116 [01:31<00:00,  1.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 9/40, Train Loss: 11.9023, Train Acc: 0.0019, Val Loss: 12.5478, Val Acc: 0.2267\n","Model saved to /content/drive/My Drive/Tugas Akhir/NARM/NARM.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/40: 100%|██████████| 2079/2079 [04:11<00:00,  8.26it/s, loss=12.2636, acc=0.0021]\n","Testing: 100%|██████████| 116/116 [01:32<00:00,  1.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 10/40, Train Loss: 11.8865, Train Acc: 0.0021, Val Loss: 12.5483, Val Acc: 0.2436\n","Model saved to /content/drive/My Drive/Tugas Akhir/NARM/NARM.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 11/40: 100%|██████████| 2079/2079 [04:13<00:00,  8.21it/s, loss=11.3012, acc=0.0022]\n","Testing: 100%|██████████| 116/116 [01:30<00:00,  1.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 11/40, Train Loss: 11.8702, Train Acc: 0.0022, Val Loss: 12.5490, Val Acc: 0.2436\n","Model saved to /content/drive/My Drive/Tugas Akhir/NARM/NARM.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 12/40: 100%|██████████| 2079/2079 [04:10<00:00,  8.31it/s, loss=11.3239, acc=0.0021]\n","Testing: 100%|██████████| 116/116 [01:31<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 12/40, Train Loss: 11.8684, Train Acc: 0.0021, Val Loss: 12.5490, Val Acc: 0.2453\n","Model saved to /content/drive/My Drive/Tugas Akhir/NARM/NARM.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 13/40: 100%|██████████| 2079/2079 [04:12<00:00,  8.23it/s, loss=11.8000, acc=0.0022]\n","Testing: 100%|██████████| 116/116 [01:30<00:00,  1.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 13/40, Train Loss: 11.8668, Train Acc: 0.0022, Val Loss: 12.5488, Val Acc: 0.2453\n","Model saved to /content/drive/My Drive/Tugas Akhir/NARM/NARM.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 14/40: 100%|██████████| 2079/2079 [04:24<00:00,  7.86it/s, loss=11.3685, acc=0.0022]\n","Testing: 100%|██████████| 116/116 [01:31<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 14/40, Train Loss: 11.8647, Train Acc: 0.0022, Val Loss: 12.5490, Val Acc: 0.2470\n","Model saved to /content/drive/My Drive/Tugas Akhir/NARM/NARM.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 15/40: 100%|██████████| 2079/2079 [04:12<00:00,  8.23it/s, loss=12.7302, acc=0.0022]\n","Testing: 100%|██████████| 116/116 [01:31<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 15/40, Train Loss: 11.8635, Train Acc: 0.0022, Val Loss: 12.5484, Val Acc: 0.2453\n","Model saved to /content/drive/My Drive/Tugas Akhir/NARM/NARM.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 16/40: 100%|██████████| 2079/2079 [04:12<00:00,  8.22it/s, loss=11.7902, acc=0.0023]\n","Testing: 100%|██████████| 116/116 [01:31<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 16/40, Train Loss: 11.8614, Train Acc: 0.0023, Val Loss: 12.5485, Val Acc: 0.2470\n","Model saved to /content/drive/My Drive/Tugas Akhir/NARM/NARM.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 17/40: 100%|██████████| 2079/2079 [04:11<00:00,  8.26it/s, loss=11.7014, acc=0.0022]\n","Testing: 100%|██████████| 116/116 [01:30<00:00,  1.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 17/40, Train Loss: 11.8622, Train Acc: 0.0022, Val Loss: 12.5486, Val Acc: 0.2470\n","Model saved to /content/drive/My Drive/Tugas Akhir/NARM/NARM.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 18/40: 100%|██████████| 2079/2079 [04:08<00:00,  8.36it/s, loss=11.7667, acc=0.0023]\n","Testing: 100%|██████████| 116/116 [01:31<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 18/40, Train Loss: 11.8615, Train Acc: 0.0023, Val Loss: 12.5485, Val Acc: 0.2470\n","Model saved to /content/drive/My Drive/Tugas Akhir/NARM/NARM.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 19/40: 100%|██████████| 2079/2079 [04:10<00:00,  8.31it/s, loss=11.4386, acc=0.0023]\n","Testing: 100%|██████████| 116/116 [01:31<00:00,  1.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 19/40, Train Loss: 11.8612, Train Acc: 0.0023, Val Loss: 12.5485, Val Acc: 0.2504\n","Model saved to /content/drive/My Drive/Tugas Akhir/NARM/NARM.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 20/40: 100%|██████████| 2079/2079 [04:10<00:00,  8.30it/s, loss=11.3474, acc=0.0023]\n","Testing: 100%|██████████| 116/116 [01:30<00:00,  1.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 20/40, Train Loss: 11.8606, Train Acc: 0.0023, Val Loss: 12.5484, Val Acc: 0.2504\n","Model saved to /content/drive/My Drive/Tugas Akhir/NARM/NARM.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 21/40: 100%|██████████| 2079/2079 [04:11<00:00,  8.27it/s, loss=12.0587, acc=0.0023]\n","Testing: 100%|██████████| 116/116 [01:30<00:00,  1.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 21/40, Train Loss: 11.8613, Train Acc: 0.0023, Val Loss: 12.5485, Val Acc: 0.2504\n","Model saved to /content/drive/My Drive/Tugas Akhir/NARM/NARM.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 22/40: 100%|██████████| 2079/2079 [04:09<00:00,  8.35it/s, loss=11.9349, acc=0.0023]\n","Testing: 100%|██████████| 116/116 [01:30<00:00,  1.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 22/40, Train Loss: 11.8612, Train Acc: 0.0023, Val Loss: 12.5485, Val Acc: 0.2504\n","Model saved to /content/drive/My Drive/Tugas Akhir/NARM/NARM.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 23/40: 100%|██████████| 2079/2079 [04:08<00:00,  8.37it/s, loss=11.9278, acc=0.0023]\n","Testing: 100%|██████████| 116/116 [01:30<00:00,  1.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 23/40, Train Loss: 11.8605, Train Acc: 0.0023, Val Loss: 12.5485, Val Acc: 0.2504\n","Model saved to /content/drive/My Drive/Tugas Akhir/NARM/NARM.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 24/40: 100%|██████████| 2079/2079 [04:22<00:00,  7.92it/s, loss=11.9159, acc=0.0023]\n","Testing: 100%|██████████| 116/116 [01:30<00:00,  1.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 24/40, Train Loss: 11.8607, Train Acc: 0.0023, Val Loss: 12.5485, Val Acc: 0.2504\n","Early stopping triggered after 24 epochs\n","Model saved to /content/drive/My Drive/Tugas Akhir/NARM/NARM_final.pt\n"]}]},{"cell_type":"code","source":["k = 20\n","\n","res, loss = test(best_model, test_loader, k=k, validation=False, log_results=False)\n","print()\n","\n","print(f\"Overall Test Results\")\n","print(f\"  Loss: {loss:.4f}\")\n","print(f\"  Hit@{k}: {res.overall.hit_at_k:.4f}%\")\n","print(f\"  MRR@{k}: {res.overall.mrr_at_k:.4f}%\")\n","print(f\"  Accuracy: {res.overall.accuracy:.4f}%\")\n","\n","# add detail for every session category\n","print()\n","print(\"Short Session:\")\n","print(f\"  Accuracy: {res.short.accuracy:.4f}%\")\n","print(f\"  Hit@{k}: {res.short.hit_at_k:.4f}%\")\n","print(f\"  MRR@{k}: {res.short.mrr_at_k:.4f}%\")\n","\n","print()\n","print(\"Medium Session:\")\n","print(f\"  Accuracy: {res.medium.accuracy:.4f}%\")\n","print(f\"  Hit@{k}: {res.medium.hit_at_k:.4f}%\")\n","print(f\"  MRR@{k}: {res.medium.mrr_at_k:.4f}%\")\n","\n","print()\n","print(\"Long Session:\")\n","print(f\"  Accuracy: {res.long.accuracy:.4f}%\")\n","print(f\"  Hit@{k}: {res.long.hit_at_k:.4f}%\")\n","print(f\"  MRR@{k}: {res.long.mrr_at_k:.4f}%\")"],"metadata":{"id":"03K6vpnnGOEW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746804900481,"user_tz":-420,"elapsed":99723,"user":{"displayName":"18221083 Nazhif Haidar Putra Wibowo","userId":"14295694113135502399"}},"outputId":"3dd5d743-1a02-47b2-8785-6940be3531a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Testing: 100%|██████████| 116/116 [01:39<00:00,  1.16it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Overall Test Results\n","  Loss: 12.5357\n","  Hit@20: 1.3517%\n","  MRR@20: 0.4768%\n","  Accuracy: 0.2572%\n","\n","Short Session:\n","  Accuracy: 0.3128%\n","  Hit@20: 1.5122%\n","  MRR@20: 0.5602%\n","\n","Medium Session:\n","  Accuracy: 0.1975%\n","  Hit@20: 1.1703%\n","  MRR@20: 0.3837%\n","\n","Long Session:\n","  Accuracy: 0.0572%\n","  Hit@20: 0.8295%\n","  MRR@20: 0.1989%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["## Disconnect so that my bill will not raise"],"metadata":{"id":"IzzulbZQG8FP"}},{"cell_type":"code","source":["# from google.colab import runtime\n","# runtime.unassign()"],"metadata":{"id":"Q67gfXkTDT-t"},"execution_count":null,"outputs":[]}]}